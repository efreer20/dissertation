---
title: "3a"
author: "Emily Bovee"
date: "5/15/2019"
output: html_document
---
# Common Code Bank for All Multivariate Random Forest Models
```{r}
#----------------------Load relevant libraries
library(MultivariateRandomForest)
library(pROC)
library(tidyverse)
library(beepr)
library(doParallel)
library(foreach)
library(randomForest)
setwd("/Volumes/Linnen Lab/MSU Engineering/PROJECTS/Emily Dissertation/*May 2019 Party*")
getwd()
#----------------------Load relevant data
  # Use the output of the Merge!.R file: randomforestdata.csv

#using imputation 2 because that was the dataset that I randomly selected to use for this analysis

data <- read_csv("randomforestdata_3.18.19_withURM.csv")

#-------Delete listwise
#Remove nas from the dataset
RFdata <- na.omit(data)  


#----------------------Set seed
set.seed(2020)
#----------------------Set up relevant functions

#------- cv function
  #taken from the documentation for Amelia Package
  #adding the set.seed argument
cvData = function (X, Y, F, seed=2020) {
  DrugNumber = nrow(Y)
  Index = 1:DrugNumber
  FoldedIndex = NULL
  FF = F - 1
  for (i in 1:FF) {
    set.seed(seed)
    FoldedIndex[[i]] = sample(Index, floor(DrugNumber/F))
    Index = setdiff(Index, FoldedIndex[[i]])
    if (i == FF) {
      FoldedIndex[[i + 1]] = Index
    }
  }
  TestingIndex = NULL
  TrainingIndex = NULL
  TrainingData = NULL
  TestingData = NULL
  OutputTrain = NULL
  OutputTest = NULL
  for (i in 1:F) {
    TestingIndex[[i]] = FoldedIndex[[i]]
    TrainingIndex[[i]] = setdiff(1:DrugNumber, TestingIndex[[i]])
    TrainingData[[i]] = X[TrainingIndex[[i]], , drop = FALSE]
    TestingData[[i]] = X[TestingIndex[[i]], , drop = FALSE]
    OutputTrain[[i]] = Y[TrainingIndex[[i]], , drop = FALSE]
    OutputTest[[i]] = Y[TestingIndex[[i]], , drop = FALSE]
  }
  result = list(TrainingData, TestingData, OutputTrain, OutputTest, 
                FoldedIndex)
  return(result)
}

#The GitHub Repository from which this is derived
#https://github.com/cran/MultivariateRandomForest/blob/master/R/CrossValidation.R

```

Specify only the variables needed for 3a

```{r}
colnames(RFdata)

#selecting only the variables that are needed for this specific analysis
RFdata <- RFdata %>% 
                select(c(
                  "FEMALE",
                  "URM",
                  "FIRSTGEN",
                  "Max_ACT_Composite",   
                  "SouthcomplexBinary_2015",
                  "V1_ESE",
                  "V1_Val",
                  "SS18_Persistence"
                ))


#put(outcome/s) at the front of the dataset
RFdata <- RFdata %>% 
  select(SS18_Persistence, everything())

```

# Random Forest

```{r}
#------------
#Generate matrices from dataset in order to later do cross-validation
#------------
#The arguments I need for cross-validation
        #X	      M x N Input matrix, M is the number of samples and N is the number of features
        #Y	      output responses as column vector
        #F	      Number of Folds


#---------- Create X and Y
              # X is my data frame in a matrix format with just the features / covariates for the 
                  #model
              # Y is my data frame again in a matrix format with just the dependent variables


#Creating the x input matrix (predictors)
  #Make a matrix of predictor variables, for training X, exclude outcome
 X = data.matrix (RFdata [, -(1)])
 
#Creating the Y input matrix (outcome)
  #Make a matrix for training Y - outcome variables only
  Y = data.matrix (RFdata [, (1)])
  
###--------------------------------- 
#Further Reading
###---------------------------------  
#More about creating a matrix from a dataframe
      #https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.matrix.html

# More about subsetting matrices
# http://astrostatistics.psu.edu/su07/R/html/base/html/subset.html

###---------------------------------  
#Notes
###---------------------------------  
  ###NOTE TO SELF: Make sure data is in the correct order because this calls on you to ignore certain variables and it's important to know the order of the variables in order for this to make sense
                #for example: the X matrix has -(1:2), meaning we want to exclude the first two rows
                #the second matrix has 1, 
```


```{r}

# generate dataset for cross-validation

crossData <- cvData(X, Y, F=5, seed=3)
xTrainList = crossData[[1]]
xTestList = crossData[[2]]
yTrainList = crossData[[3]]
yTestList = crossData[[4]]

```

```{r}
#-------parameters for the random forest
n_tree=5
m_feature=5
min_leaf=5

#-------For Loop to run the random forest itself
preds = NULL

cl <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cl)

for(ii in 1:length(xTrainList)){
  # organize data to run on one fold of cross-validated data
  trainX = xTrainList[[ ii ]]
  trainY = yTrainList[[ ii ]]
  testX = xTestList[[ ii ]]
  testY = yTestList[[ii]]

  # generate predictions for that fold
  foldPreds = build_forest_predict(
    trainX, trainY, n_tree, m_feature, min_leaf, testX
    )  
  
  # organize into big preds df
  colnames(foldPreds) = paste0('yhat_',1:ncol(foldPreds))
  colnames(testY) = paste0('y_',1:ncol(testY))
  foldPreds = cbind(foldPreds, testY)
  preds = rbind(preds, foldPreds)
}

stopCluster(cl)
registerDoSEQ()

dim(preds)
head(preds)

## Rename the preds df to correspond to this specific one that I'm on

model_3a <- preds
```

# Performance Evaluation
```{r}
# Performance Evaluation
#--------------------------Residuals
#save predictions + actual as a dataframe
preds.df <- as.data.frame(model_3a)

#Create a function to calculate the (predicted - actual: RESIDUAL)
  #take the absolute value
residuals<- function(pred, obs){
  diff <- pred-obs
  return(abs(diff))
}

#apply that function
mod3a_resid <- residuals(preds.df$yhat_1, preds.df$y_1)

#plot the errors in a density plot

resid_plot <- plot(density(mod3a_resid), 
                          main = "Absolute Value of Residuals for Mot-Persistence Model",
                          xlab = "Residuals",
                          ylab = "Density")

##Compare the above area under the curve /ROC to baseline model
ROC_3a <-roc(preds.df$y_1, preds.df$yhat_1)
  #ROC takes Actual
  #then predictor

ROC_3a_plot <- plot(ROC_3a, print.auc = TRUE)


#tell me when you're done
beep()
```


```{r}
#Variance Explained 7.28.19

#R2
cor(preds.df$yhat_1, preds.df$y_1, method = 'pearson')^2


```
